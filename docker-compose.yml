services:
  # ==================== INFRASTRUCTURE ====================
  
  # Zookeeper for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper-demo
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - cuet-api-avengers
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Kafka
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka-demo
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - cuet-api-avengers
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui-demo
    ports:
      - "8080:8080"
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_CLUSTERS_0_NAME: "local-kafka"
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    networks:
      - cuet-api-avengers

  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger-demo
    ports:
      - "16686:16686"  # UI
      - "14268:14268"  # HTTP collector
      - "14250:14250"  # gRPC collector
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
    networks:
      - cuet-api-avengers

  # ==================== DATABASES ====================
  
  # PostgreSQL for User Service
  postgres-user:
    image: postgres:15-alpine
    container_name: postgres-user-demo
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: userdb
    ports:
      - "5433:5432"
    volumes:
      - ./data/user:/var/lib/postgresql/data
    networks:
      - cuet-api-avengers
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d userdb"]
      interval: 10s
      timeout: 5s
      retries: 5

  # PostgreSQL for Campaign Service
  postgres-campaign:
    image: postgres:15-alpine
    container_name: postgres-campaign-demo
    environment:
      POSTGRES_USER: campaign
      POSTGRES_PASSWORD: password
      POSTGRES_DB: campaigndb
    ports:
      - "5434:5432"
    volumes:
      - ./data/campaign:/var/lib/postgresql/data
    networks:
      - cuet-api-avengers
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U campaign -d campaigndb"]
      interval: 10s
      timeout: 5s
      retries: 5

  # PostgreSQL for Notification Service
  postgres-notification:
    image: postgres:15-alpine
    container_name: postgres-notification-demo
    environment:
      POSTGRES_USER: notification_user
      POSTGRES_PASSWORD: notification_pass
      POSTGRES_DB: notification_db
    ports:
      - "5435:5432"
    volumes:
      - ./data/notification:/var/lib/postgresql/data
    networks:
      - cuet-api-avengers
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U notification_user -d notification_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # PostgreSQL for Payment Service
  postgres-payment:
    image: postgres:15-alpine
    container_name: postgres-payment-demo
    environment:
      POSTGRES_USER: payment_user
      POSTGRES_PASSWORD: payment_pass
      POSTGRES_DB: payment_db
    ports:
      - "5436:5432"
    volumes:
      - ./data/payment:/var/lib/postgresql/data
    networks:
      - cuet-api-avengers
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U payment_user -d payment_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for Gateway
  redis:
    image: redis:7-alpine
    container_name: redis-demo
    ports:
      - "6379:6379"
    networks:
      - cuet-api-avengers
    volumes:
      - ./data/redis:/data
    # command: redis-server --appendonly yes

  # ==================== SERVICES ====================

  # User Service
  user-service:
    # image: sleepytmzd/user-service:v4
    build:
      context: ./user-service
      dockerfile: Dockerfile
    container_name: user-service-demo
    ports:
      - "8001:8001"
    environment:
      DATABASE_URL: postgresql+asyncpg://user:password@postgres-user:5432/userdb
      JAEGER_ENDPOINT: http://jaeger-demo:14268/api/traces
      TRACING_ENABLED: "true"
      SERVICE_NAME: "user-service"
    depends_on:
      postgres-user:
        condition: service_healthy
      jaeger:
        condition: service_started
    networks:
      - cuet-api-avengers
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service,version"
    labels:
      - "service=user-service"
      - "version=v4"

  # Campaign Service
  campaign-service:
    # image: sleepytmzd/campaign-service:v1
    build:
      context: ./campaign-service
      dockerfile: Dockerfile
    container_name: campaign-service-demo
    ports:
      - "8002:8002"
    environment:
      DATABASE_URL: postgresql://campaign:password@postgres-campaign:5432/campaigndb
      REDIS_URL: redis://redis:6379
      JAEGER_ENDPOINT: http://jaeger-demo:14268/api/traces
      TRACING_ENABLED: "true"
      SERVICE_NAME: "campaign-service"
      DEBUG: "false"
    depends_on:
      postgres-campaign:
        condition: service_healthy
      redis:
        condition: service_started
      jaeger:
        condition: service_started
    networks:
      - cuet-api-avengers
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service,version"
    labels:
      - "service=campaign-service"
      - "version=v1"

  # Notification Service
  notification-service:
    build:
      context: ./notification-service
      dockerfile: Dockerfile
    container_name: notification-service-demo
    ports:
      - "8005:8005"
    environment:
      DATABASE_URL: postgresql+asyncpg://notification_user:notification_pass@postgres-notification:5432/notification_db
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      SERVICE_NAME: "notification-service"
      SERVICE_PORT: 8005
    depends_on:
      postgres-notification:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - cuet-api-avengers
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8005/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service,version"
    labels:
      - "service=notification-service"
      - "version=v1"

  # Payment Service
  payment-service:
    build:
      context: ./payment-service
      dockerfile: Dockerfile
    container_name: payment-service-demo
    ports:
      - "8003:8003"
    environment:
      DATABASE_URL: postgresql+asyncpg://payment_user:payment_pass@postgres-payment:5432/payment_db
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      JAEGER_ENDPOINT: http://jaeger-demo:14268/api/traces
      TRACING_ENABLED: "true"
      SERVICE_NAME: "payment-service"
      SERVICE_PORT: 8003
    depends_on:
      postgres-payment:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - cuet-api-avengers
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service,version"
    labels:
      - "service=payment-service"
      - "version=v1"

  
  # API Gateway
  api-gateway:
    # image: sleepytmzd/ecom-api-gateway:v3
    build:
      context: ./api-gateway
      dockerfile: Dockerfile
    container_name: ecom-api-gateway-demo
    ports:
      - "8000:8000"
    environment:
      JWT_SECRET: your-super-secret-jwt-key-change-in-production
      RATE_LIMIT_ENABLED: true
      CACHE_ENABLED: true
      CIRCUIT_BREAKER_ENABLED: true
      REDIS_URL: redis://redis:6379
      USER_SERVICE_URL: http://user-service:8001
      CAMPAIGN_SERVICE_URL: http://campaign-service:8002
      JAEGER_ENDPOINT: http://jaeger-demo:14268/api/traces
      TRACING_ENABLED: "true"
      SERVICE_NAME: "api-gateway"
    depends_on:
      - redis
      - user-service
      - campaign-service
      - jaeger
    networks:
      - cuet-api-avengers
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service,version"
    labels:
      - "service=api-gateway"
      - "version=v3"

# # ==================== MONITORING ====================

#   prometheus:
#     image: prom/prometheus:latest
#     container_name: prometheus-demo
#     volumes:
#       - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
#     ports:
#       - "9090:9090"
#     networks:
#       - cuet-api-avengers
#     depends_on:
#       - user-service
#       - demo-service
#       - api-gateway

#   grafana:
#     image: grafana/grafana:latest
#     container_name: grafana-demo
#     ports:
#       - "3000:3000"
#     environment:
#       GF_SECURITY_ADMIN_USER: admin
#       GF_SECURITY_ADMIN_PASSWORD: admin
#     volumes:
#       - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
#       - grafana_data:/var/lib/grafana
#     depends_on:
#       - prometheus
#       - loki
#     networks:
#       - cuet-api-avengers


#   loki:
#     image: grafana/loki:3.0.0
#     container_name: loki-demo
#     ports:
#       - "3100:3100"
#     volumes:
#       - ./monitoring/loki-config.yml:/etc/loki/local-config.yaml
#       - loki_data:/loki
#     command: -config.file=/etc/loki/local-config.yaml
#     networks:
#       - cuet-api-avengers
#     healthcheck:
#       test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3100/ready"]
#       interval: 30s
#       timeout: 10s
#       retries: 3
#       start_period: 40s

#   promtail:
#     image: grafana/promtail:3.0.0
#     container_name: promtail-demo
#     volumes:
#       - ./monitoring/promtail-config.yml:/etc/promtail/config.yml
#       - /var/log:/var/log:ro
#       - /var/lib/docker/containers:/var/lib/docker/containers:ro
#       - /var/run/docker.sock:/var/run/docker.sock:ro
#     command: -config.file=/etc/promtail/config.yml
#     networks:
#       - cuet-api-avengers
#     depends_on:
#       - loki

volumes:
  loki_data:
    driver: local
  grafana_data:
    driver: local

networks:
  cuet-api-avengers:
    driver: bridge
